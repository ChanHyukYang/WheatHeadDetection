{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Yolo Model",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0yIRMF5PcAm7",
        "colab_type": "text"
      },
      "source": [
        "# The Model "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "a4MRHlTVb2AV"
      },
      "source": [
        "Code by Hmrishav Bandyopadhyay\n",
        "https://towardsdatascience.com/real-time-object-detection-pytorch-yolo-f7fec35afb64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from lib.train_AI_lib import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "os.chdir('..')\n",
        "print(os.getcwd())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import cv2\n",
        "#### Filters we want to use ####\n",
        "edgeDetect  = lambda oImg: cv2.Canny(oImg, 125, 200)\n",
        "edgeDetect2 = lambda fImg: cv2.Canny(fImg, 175, 250)\n",
        "laplacian   = lambda pImg: cv2.Laplacian(cv2.cvtColor(pImg, cv2.COLOR_BGR2GRAY),cv2.CV_64F)\n",
        "gradient    = lambda gImg: cv2.morphologyEx(cv2.cvtColor(gImg, cv2.COLOR_BGR2GRAY), cv2.MORPH_GRADIENT, (5,5))\n",
        "opening     = lambda cImg: cv2.morphologyEx(cv2.cvtColor(cImg, cv2.COLOR_BGR2GRAY), cv2.MORPH_OPEN, kernel)\n",
        "bilateral   = lambda bImg: cv2.bilateralFilter(cv2.cvtColor(bImg, cv2.COLOR_BGR2GRAY),9,100,100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nbg6AtavZLYY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import  nn\n",
        "\n",
        "#o = [i + 2*p - k - (k-1)*(d-1)]/s + 1--formula to calculate padding\n",
        "\n",
        "\n",
        "class YoloNet(nn.Module):\n",
        "\n",
        "    #YOLO model\n",
        "    '''\n",
        "    Input size of the model is \n",
        "    448x448x3\n",
        "    In tensor notation, expressed as [batchsize,3,448,448]\n",
        "    output--\n",
        "    [batchsize,30,7,7]\n",
        "    '''\n",
        "\n",
        "    def __init__(self,name):\n",
        "        super(YoloNet,self).__init__()\n",
        "        self.name = name\n",
        "\n",
        "        self.t1=nn.Sequential(\n",
        "            nn.Conv2d(in_channels=3,out_channels=64,kernel_size=(7,7),stride=2,padding=(2,2)),\n",
        "            nn.MaxPool2d(kernel_size=(2,2),stride=2),\n",
        "        )\n",
        "        \n",
        "        self.t2=nn.Sequential(\n",
        "            nn.Conv2d(in_channels=64,out_channels=192,kernel_size=(3,3),padding=(1,1)),\n",
        "            nn.MaxPool2d(kernel_size=(2,2),stride=2),\n",
        "        )\n",
        "        self.t3=nn.Sequential(\n",
        "            nn.Conv2d(in_channels=192,out_channels=128,kernel_size=(1,1)),\n",
        "            nn.Conv2d(in_channels=128,out_channels=256,kernel_size=(3,3),padding=(1,1)),\n",
        "            nn.Conv2d(in_channels=256,out_channels=256,kernel_size=(1,1)),\n",
        "            nn.Conv2d(in_channels=256,out_channels=512,kernel_size=(3,3),padding=(1,1)),\n",
        "            nn.MaxPool2d(kernel_size=(2,2),stride=2),\n",
        "        )\n",
        "\n",
        "        self.t4=nn.Sequential(\n",
        "            nn.Conv2d(in_channels=512,out_channels=256,kernel_size=(1,1)),\n",
        "            nn.Conv2d(in_channels=256,out_channels=512,kernel_size=(3,3),padding=(1,1)),\n",
        "            nn.Conv2d(in_channels=512,out_channels=256,kernel_size=(1,1)),\n",
        "            nn.Conv2d(in_channels=256,out_channels=512,kernel_size=(3,3),padding=(1,1)),\n",
        "            nn.Conv2d(in_channels=512,out_channels=256,kernel_size=(1,1)),\n",
        "            nn.Conv2d(in_channels=256,out_channels=512,kernel_size=(3,3),padding=(1,1)),\n",
        "            nn.Conv2d(in_channels=512,out_channels=256,kernel_size=(1,1)),\n",
        "            nn.Conv2d(in_channels=256,out_channels=512,kernel_size=(3,3),padding=(1,1)),\n",
        "            nn.Conv2d(in_channels=512,out_channels=512,kernel_size=(1,1)),\n",
        "            nn.Conv2d(in_channels=512,out_channels=1024,kernel_size=(3,3),padding=(1,1)),\n",
        "\n",
        "            nn.Conv2d(in_channels=1024,out_channels=1024,kernel_size=(3,3),stride=2)\n",
        "        )\n",
        "\n",
        "        self.t5=nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1024,out_channels=512,kernel_size=(1,1)),\n",
        "            nn.Conv2d(in_channels=512,out_channels=1024,kernel_size=(3,3),padding=(1,1)),\n",
        "            nn.Conv2d(in_channels=1024,out_channels=512,kernel_size=(1,1)),\n",
        "            nn.Conv2d(in_channels=512,out_channels=1024,kernel_size=(3,3),padding=(1,1)),\n",
        "\n",
        "            nn.Conv2d(in_channels=1024,out_channels=1024,kernel_size=(3,3),padding=(1,1)),\n",
        "\n",
        "            nn.Conv2d(in_channels=1024,out_channels=1024,kernel_size=(3,3),stride=2,padding=(1,1))\n",
        "\n",
        "        )\n",
        "\n",
        "        self.t6=nn.Sequential(\n",
        "            nn.Conv2d(in_channels=1024,out_channels=1024,kernel_size=(3,3),padding=(1,1)),\n",
        "            nn.Conv2d(in_channels=1024,out_channels=1024,kernel_size=(3,3),padding=(1,1))\n",
        "        )\n",
        "\n",
        "\n",
        "        \n",
        "    def forward(self,x):\n",
        "        x=self.t1(x)\n",
        "        x=self.t2(x)\n",
        "        x=self.t3(x)\n",
        "        x=self.t4(x)\n",
        "        x=self.t5(x)\n",
        "        x=self.t6(x)\n",
        "        \n",
        "        x=torch.flatten(x,1)\n",
        "        x=nn.Linear(x.size()[1],4096)(x)\n",
        "        x=nn.Linear(4096,7*7*30)(x)\n",
        "        x=x.view(-1,30,7,7)\n",
        "\n",
        "        return x #output of model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhYgcL0yblI3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainLoader, valLoader, testLoader = loadData(batchsize = 32, args = {'func': edgeDetect2})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "my_model = CNN(name = \"edgeDetect2\")\n",
        "use_cuda = True\n",
        "\n",
        "if use_cuda and torch.cuda.is_available():\n",
        "  my_model.cuda()\n",
        "  print('CUDA is available!  Training on GPU ...')\n",
        "else:\n",
        "  print('CUDA is not available.  Training on CPU ...')\n",
        "\n",
        "trainNet(net = my_model,\n",
        "         data = [trainLoader, valLoader], \n",
        "         batchsize = 32, \n",
        "         epochNo = 15, \n",
        "         lr = 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dir = \"/content/drive/My Drive/OpenCV Model/edgedetect2_b64_te10_lr0.001\"\n",
        "if not os.path.exists(dir):\n",
        "    os.mkdir(dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#net = exNetClass('netA'); net.cuda()\n",
        "netPath = '/content/drive/My Drive/OpenCV Model/edgedetect2_b64_te10_lr0.001'\n",
        "#net.load_state_dict(torch.load(netPath+'/model_epoch9'))\n",
        "trainLoader, valLoader, testLoader = loadData(batchsize = 1, args = {'func': edgeDetect2})\n",
        "_ = regresAnalysis(my_model, trainLoader, netPath)"
      ]
    }
  ]
}